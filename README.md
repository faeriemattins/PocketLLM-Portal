# PocketLLM-Portal
A lightweight LLM-powered web application designed to run inference on a budget CPU with a local cache
